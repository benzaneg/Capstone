{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What precisely do you plan to do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I plan to pull in news sources on issues which are of local, municipal or state importance and interrgotate the coverage between local papers and natioanl news outlets. I would be breaking up the coverage into two groups, one being the local papers of the city, and the other being, national papers, who for whatever reason have taken up local subject matter. The idea is to compare how events are covered from a local and national lens using chunking, topic classification, cosine simialirty, etc. to find out the statistical diffrences between the coverage of the two. \n",
    "\n",
    "> Depending on how far I get in POS, Chunking model creation and Semantic creation this could be the meat of my project, but I hope to apply it outside of that context.\n",
    "\n",
    "> I hope to train a model off of one of the large tree bank datasets WSJ Corpora (https://catalog.ldc.upenn.edu/LDC2000T43), NYTimes (https://groups.google.com/forum/#!forum/nytnlp) to identify diffrent we ways I csn POS, chunking to draw conclusions from an event. I would also like to look into semantic's of a text to build off of it using FrameNet (https://web.stanford.edu/~jurafsky/slp3/6.pdf). These togethere would be applied to article which I found surrounding an event. The event I am leaning towards analyzing is the Hurrican Harvey but I have multiple others ideas for the event itself but that is not quite as big as a problem. I will start with pulling stories related to an event to create a narrative using this news aggreation company by scraping coverage which the Washington Post and NYTimes did and from my curosry look I'll have to scrape the local papers by hand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What type of model will you need to develop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The semantic and POS and chunking classification model will be the most robust portion of my capstone in a technical, model sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What metrics will you be using to assess performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Well since I'll be doing classification I'll be exploring how my model works with confusion matrixs, f1 score, AUC-Roc, etc. If I get to it and can apply a cross anlysis of the diffrent news papers and their information and extract some meaningful comparisons.\n",
    "\n",
    "> When looking into a comparison between the two \"sources\" of news I hope to do a cosine similairty, look into using gini/entropy model, other types of comparison like those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is your project appropriately scoped?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The project is aggressive with the various comnents I want to fine tune before I start to analyze journalists pursuits but as long as GA sees me in in creating the POS-Chunking model as a success and everything else on top as gravy I think it is apporpiately sized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it too aggressive? Too easy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I think that I have a lot in front of me, but as long as I break it up into mangeable chucks to accomplish various portions I want to hit during the the process I will be okay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does anyone care about this? Why should people be interested in your results? What value will the completion of your project be adding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The value of the project is important in the discussion on how we have heard about the shrinking of local news markets, while those discussions have more complexity than most people realize though (https://www.economist.com/united-states/2018/06/23/small-town-american-newspapers-are-surprisingly-resilient), and how exchange will affect how reporting on local events, far from information centers will be changed over time. I also think it is important to see how local news cover stuff in their terriotory veruss a national news outlet does. How those two entities can learn from each other in coverage, in the local communitties thoughts, and in the national scope.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This has been a moving target for me. My first set of the data will be using and exploring the datasets listed above from WSJ, NYTimes, and FrameNet to create or find the ways I will be draweing semantic relationships, and POS Tagging and chunking. These places will help me try and formalize how I want to approach the first questions and then from there I will be moving froward and trying to see how everything will work in conjuction with each other. \n",
    "\n",
    "> Regardless if I use these predetemined methods for analyzing my data I will need to pull full text versions from the NYTimes and Washington Post website to create a symbopiusm of information. These will be combined with the local news sources. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> I don't have my data in hand so I don't have any eda... I hope to be able to have my data by the end of the weekend and complete a prelimnary EDA on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
